rm -f result_dir/*
python BERT_NER.py\
    --task_name="NER"  \
    --do_lower_case=False \
    --do_train=True  \
    --do_eval=True   \
    --do_predict=True \
    --data_dir=data/ontonotes   \
    --vocab_file=cased_L-12_H-768_A-12/vocab.txt  \
    --bert_config_file=cased_L-12_H-768_A-12/bert_config.json \
    --init_checkpoint=cased_L-12_H-768_A-12/bert_model.ckpt   \
    --max_seq_length=128   \
    --train_batch_size=32   \
    --learning_rate=2e-5   \
    --num_train_epochs=3.0   \
    --output_dir=result_dir \
	--other_indice=27 \
	--from_pickle=False \
	--phase=1 \
	--proto_path=data/ontonotes/proto.pkl \
	--num_others=5
